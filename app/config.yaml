chunking:
  overlap: 50
  separators:
  - '


    '
  - '

    '
  - '. '
  - ' '
  size: 512
documents:
  auto_reindex: true
  max_file_size_mb: 50
  supported_extensions:
  - .txt
  - .pdf
  - .docx
  - .md
  - .html
  - .csv
  upload_path: data/documents/
embedding:
  batch_size: 32
  cache_dir: models
  device: cpu
  model: all-MiniLM-L6-v2
last_engine: Nvidia (Online)
local_llm:
  context_window: 4048
  last_model: Llama-3.2-3B-Instruct-Q4_K_M.gguf
  models_path: models
  threads: 4
ollama:
  base_url: http://localhost:11434
  context_window: 4096
  max_tokens: 2048
  model: llama3:8b
  temperature: 0.7
  timeout: 120
online_api:
  groq:
    default_model: llama-3.1-8b-instant
  nvidia:
    default_model: mistralai/devstral-2-123b-instruct-2512
retrieval:
  enable_reranking: true
  hybrid_alpha: 0.7
  min_score_threshold: 0.5
  rerank_model: cross-encoder/ms-marco-MiniLM-L-6-v2
  search_mode: hybrid
ui:
  max_upload_size: 50
  page_icon: app/ui/assets/Icon.png
  page_title: ILIN - Intelligence Node
vector_store:
  index_path: data/vector_indices/
  metadata_db: data/metadata.db
  rerank_top_k: 5
  top_k: 10
